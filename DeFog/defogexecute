#!/bin/bash

#########################################################################################################################
# CSC4006 - Research And Development Project
# Developed by: Jonathan McChesney (MEng Computer Games Development)
# Queen's University Belfast
#
# Component: defogexecute.sh
#
# Purpose: This script uses Secure Shell and Secure Copy Protocol to execute the actions.sh and applications.sh scripts
#			on the Cloud and Edge instances. This component also handles the calculation of metrics such as the return
#			trip time, real time factor and the full computation/communication latency time. Finally this component 
#			also parses the return data and metrics and outputs the calculated metrics to the terminal and relevant 
#			results files. This script passes the actions.sh and applications.sh to the Edge or Cloud instance.
#
#########################################################################################################################


# function to invoke Help and FAQ command line output
function executebenchmarkhelp {
		./defogexecute -?
}

# function to invoke the actions script on the cloud-edge pipeline by sshing into both the cloud and edge and calling the actions bash script
# passing the relevant variables as file parameters.
function benchmark_both_actions {
		# Use secure shell to navigate to the Cloud instance, using an identity file (awskey) username and cloud ec2 address.
		# The actions.sh script is supplied to the Cloud during the tunnelling porcess. This script is passed the actions and application inputs (sourced from defog.sh)
		echo -e "ssh into edge/cloud - cloud instance for actions and system benchmarks.."
		ssh -i $awskey $clouduser@$cloudaddress ' sudo bash -s' -- < ./actions -z $actions $applications # environment variable is set to a different value for remote invocation
		echo -e "DONE - cloud ssh session"
		echo -e
		
		# Use secure shell to navigate to the Edge instance, using a username and edge node device address.
		# The actions.sh script is supplied to the Edge during the tunnelling porcess. This script is passed the actions and application inputs (sourced from defog.sh)
		echo -e "ssh into edge instance for actions and system benchmarks.."
		ssh $edgeuser@$edgeaddress ' sudo bash -s' -- < ./actions $environment $actions $applications
		echo -e "DONE - edge ssh session"	
		echo -e
}

# function to invoke the application bash file on the cloud-edge pipeline by sshing into both the cloud and edge and calling the actions bash script
# passing the relevant variables as file parameters. The results are then transferred back from the edge as necessary.
function benchmark_both_applications {
		echo -e "ssh into edge/cloud - cloud instance for applications benchmarks.."
		ssh -i $awskey $clouduser@$cloudaddress ' sudo bash -s' -- < ./applications -z $actions $applications
		echo -e "DONE - cloud ssh session"
		echo -e
		
		echo -e "ssh into edge/cloud instance for applications benchmarks.."
		ssh $edgeuser@$edgeaddress ' sudo bash -s' -- < ./applications $environment $actions $applications
		echo -e "DONE - edge ssh session"	
		echo -e
		
		# calculate the time taken to transfer data (i.e. resutlts and data files from the edge to the local user device
		local start=$(date +%s.%N)
		local transfer_cloud=$(scp -v $edgeuser@$edgeaddress:~/defog/results/* ./ 2>&1 | grep "Transferred") 		
		local newval=${transfer_cloud//[!0-9\\ \\.]/}
		newarr1=(`echo ${newval}`);
		local end=$(date +%s.%N)
		local runtime=$( echo "$end - $start" | bc -l )
		
		# set the transfer time, bytes transfered down and bytes per second down and set to the relevant metric index
		metricsValues[3]=$runtime
		metricsValues[8]=${newarr1[1]}
		metricsValues[11]=$(bc <<< "scale=10;${metricsValues[8]}/${metricsValues[3]}")
		
		# rename verbose results file, remove old file
		cat cloudresult.txt >> $verbose_filename.txt 2>/dev/null
		rm cloudresult.txt 2>/dev/null
		
		# read in results data file, save to array, remove old file
		read -a newarr < arrresult.txt 
		rm arrresult.txt 2>/dev/null
		
		# print and save data to file
		echo -e Total bytes transferred from the edge: ${metricsValues[8]} bytes | tee -a $verbose_filename.txt
		echo Transfer both pipeline edge application results to edge device: completed in $runtime secs | tee -a $verbose_filename.txt
		echo Transfer rate from the edge: ${metricsValues[11]} bytes per second | tee -a $verbose_filename.txt
		
		# invoke the set_returned_application_metrics function to set data metrics to global array
		set_returned_application_metrics	
		
		# calculate the bytes per second down from the cloud to the edge and save to array	
		metricsValues[12]=$(bc <<< "scale=10;${metricsValues[9]}/${metricsValues[13]}")
		echo "" | tee -a $verbose_filename.txt
}

# function to invoke the actions script on the edge only pipeline by sshing into both the cloud and edge and calling the actions bash script
# passing the relevant variables as file parameters.
function benchmark_edge_actions {
		echo -e "ssh into edge instance for actions and system benchmarks.."
		ssh $edgeuser@$edgeaddress ' sudo bash -s' -- < ./actions $environment $actions $applications
		echo -e "DONE - edge ssh session"
		echo -e
		
		local start=$(date +%s.%N)
		scp $edgeuser@$edgeaddress:~/defog/results/* ./
		local end=$(date +%s.%N)
		local runtime=$( echo "$end - $start" | bc -l )
		
		cat edgeresult.txt >> $verbose_filename.txt 2>/dev/null
		rm edgeresult.txt 2>/dev/null
		
		echo -e Transfer edge action results to edge device: completed in $runtime secs | tee -a $verbose_filename.txt
		echo "" | tee -a $verbose_filename.txt
		
}

# function to invoke the application bash file on the edge only pipeline by sshing into both the cloud and edge and calling the actions bash script
# passing the relevant variables as file parameters. The results are then transferred back from the edge as necessary.
function benchmark_edge_applications {
		
		echo -e "ssh into edge instance for application benchmarks.."
		ssh	$edgeuser@$edgeaddress ' sudo bash -s' -- < ./applications $environment $actions $applications
		echo -e "DONE - edge ssh session"
		echo -e
		
		local start=$(date +%s.%N)
		local transfer_cloud=$(scp -v $edgeuser@$edgeaddress:~/defog/results/* ./ 2>&1 | grep "Transferred") 		
		local newval=${transfer_cloud//[!0-9\\ \\.]/}
		newarr1=(`echo ${newval}`);
		local end=$(date +%s.%N)
		local runtime=$( echo "$end - $start" | bc -l )
		metricsValues[3]=$runtime
		metricsValues[8]=${newarr1[1]}
		metricsValues[11]=$(bc <<< "scale=10;${metricsValues[8]}/${metricsValues[3]}")

		cat cloudresult.txt >> $verbose_filename.txt 2>/dev/null
		rm cloudresult.txt 2>/dev/null
		
		read -a newarr < arrresult.txt 
		rm arrresult.txt 2>/dev/null
		
		echo -e Total bytes transferred from the edge: ${metricsValues[8]} bytes | tee -a $verbose_filename.txt
		echo Transfer edge application results to edge device: completed in $runtime secs | tee -a $verbose_filename.txt
		echo Transfer rate from the edge: ${metricsValues[11]} bytes per second | tee -a $verbose_filename.txt
		
		set_returned_application_metrics	
		
		echo "" | tee -a $verbose_filename.txt
	
}

# function to invoke the actions script on the cloud only pipeline by sshing into both the cloud and edge and calling the actions bash script
# passing the relevant variables as file parameters.
function benchmark_cloud_actions {
		echo -e "ssh into cloud instance for actions and system benchmarks.."
		ssh -i $awskey $clouduser@$cloudaddress ' sudo bash -s' -- < ./actions $environment $actions $applications
		echo -e "DONE - cloud ssh session"
		echo -e
		
		local start=$(date +%s.%N)
		scp -i $awskey $clouduser@$cloudaddress:~/defog/results/* ./
		local end=$(date +%s.%N)
		local runtime=$( echo "$end - $start" | bc -l )
		
		cat cloudresult.txt >> $verbose_filename.txt 2>/dev/null
		rm cloudresult.txt 2>/dev/null
		
		echo -e Transfer cloud action results to edge device: completed in $runtime secs | tee -a $verbose_filename.txt
		echo "" | tee -a $verbose_filename.txt

}

# function to invoke the application bash file on the cloud only pipeline by sshing into both the cloud and edge and calling the actions bash script
# passing the relevant variables as file parameters. The results are then transferred back from the edge as necessary.
function benchmark_cloud_applications {
		
		echo -e "ssh into cloud instance for application benchmarks.."
		ssh -i $awskey $clouduser@$cloudaddress ' sudo bash -s' -- < ./applications $environment $actions $applications
		echo -e "DONE - cloud ssh session"
		echo -e
		
		local start=$(date +%s.%N)
		local transfer_cloud=$(scp -v -i $awskey $clouduser@$cloudaddress:~/defog/results/* ./ 2>&1 | grep "Transferred") 		
		local newval=${transfer_cloud//[!0-9\\ \\.]/}
		newarr1=(`echo ${newval}`);
		local end=$(date +%s.%N)
		local runtime=$( echo "$end - $start" | bc -l )
		metricsValues[3]=$runtime
		metricsValues[8]=${newarr1[1]}
		metricsValues[11]=$(bc <<< "scale=10;${metricsValues[8]}/${metricsValues[3]}")
	
		rm returnedasset.* 2>/dev/null

		cat cloudresult.txt >> $verbose_filename.txt 2>/dev/null
		rm cloudresult.txt 2>/dev/null
		
		read -a newarr < arrresult.txt 
		rm arrresult.txt 2>/dev/null
		
		echo -e Total bytes transferred from the cloud: ${metricsValues[8]} bytes | tee -a $verbose_filename.txt
		echo Transfer cloud application results to edge device: completed in $runtime secs | tee -a $verbose_filename.txt
		echo Transfer rate from the cloud: ${metricsValues[11]} bytes per second | tee -a $verbose_filename.txt
		
		set_returned_application_metrics		
					
		echo "" | tee -a $verbose_filename.txt
		
}

# calculate the cost of running the benchmarks on the cloud, using AWS pricing strategy
function calc_cloud_cost {

	# initialise local variables: hourly cost of computation on AWS, convertor scalar value, cost per second and compute time.
	local awshrcost=0.016
	local convert=3600
	local awsseccost=$(bc <<< "scale=10;$awshrcost/$convert") # scale=10 sets the number of decimal places to 10
	local minruntime=60
	local computetime=${metricsValues[1]}
	
	# deterime the cost of running on AWS using the bc utility package
	local cost=$(bc <<< "$computetime*$awsseccost")
	
	# update the metric array
	metricsValues[6]=$cost
	
	# output the results to file and the terminal using tee
	echo -e "Cloud cost for application computation (£0.016 per hour)": £$cost | tee -a $verbose_filename.txt
	
}

# Estimage the cost of running the benchmarks on the edge using a cheaper AWS pricing strategy (50% of AWS cost)
function calc_edge_cost {
	
	# initialise the local variables - Estimated cost based upon AWS pricing strategy
	local edgehrcost=0.008
	local convert=3600
	local edgeseccost=$(bc <<< "scale=10;$edgehrcost/$convert") # scale=10 sets the number of decimal places to 10
	local computetime=${metricsValues[1]}
	
	# deterime the cost of running on AWS using the bc utility package
	local cost=$(bc <<< "$computetime*$edgeseccost")
		
	# update the metric array
	metricsValues[6]=$cost
	
	# output the results to file and the terminal using tee
	echo -e "Edge cost for application computation (estimated £0.008 per hour)": £$cost | tee -a $verbose_filename.txt

}

# calculate the return trip time and communication latency metrics
function calc_rtt {

	local T1=${metricsValues[0]} 
	local E=${metricsValues[1]} 
	local T3=${metricsValues[3]} 
	
	if  [ "${metricsValues[13]}" == "NA" ];
	then
		local T4=0
	else 
		local T4=${metricsValues[13]}
	fi
	
	local cl=$(bc <<< "$T1+$T3") # communication latency
	local rtt=$(bc <<< "$T1+$T3+$E") # round trip time
	local fcl=$(bc <<< "$T1+$T3+$T4") # communication latency
	local frtt=$(bc <<< "$T1+$T3+$E+$T4") # round trip time

	metricsValues[4]=$rtt # time to transfer data to and from cloud/edge as well as computation time
	metricsValues[14]=$cl # time to transfer data to and from cloud/edge
	metricsValues[15]=$frtt # time to transfer data to and from cloud/edge as well as computation time
	metricsValues[16]=$fcl # time to transfer data to and from cloud/edge
	
	echo -e Round Trip Time: $rtt secs | tee -a $verbose_filename.txt

}

# calculate real time factor for audio applications (computational time / length of audio file in seconds)
function calc_rtf {
	local computation=${newarr[1]}
	local length=${newarr[5]}
	local rtf=$(bc <<< "scale=10;$computation/$length")

	metricsValues[5]=$rtf
	
	echo Real Time Factor: $rtf secs | tee -a $verbose_filename.txt
}

# iterate over metrics returned from the edge or cloud, set them to local array
function set_returned_application_metrics {
	local mets=${#metricsValues[@]}
	local count=1
		
	if [ "${newarr[10]}" != "NA" ];
	then
		metricsValues[13]=${newarr[10]} # set time taken to transfer data from the cloud to the edge
	fi	
	
	for (( i=0; i<=$(( $mets -1 )); i++ ))
	do 
		((count++))
		
		if [ "${metricsValues[$i]}" == "NA" ] && [ "${newarr[$i]}" != "NA" ] && [ "${newarr[$i]}" ];
		then
			metricsValues[$i]=${newarr[$i]} # set retured data to local array
		fi
	done
	
}

# utility function to update the current pipeline text based on the input sourced from the defog.sh script
function set_pipeline {
		# initialise to default value
		pipeline="NA"
		
		# set the pipeline variable name to the current pipeline/platform selected, sourced from defog.sh
		if [ "$environment" == "-c" ]; then pipeline="Cloud-Only"; 
		elif [ "$environment" == "-e" ]; then pipeline="Edge-Only"; 
		elif [ "$environment" == "-b" ]; then pipeline="Cloud/Edge"; 
		fi
}

# invoke the relevant application benchmark utility function
function benchmark_applications {
		
		set_pipeline
		
		# print application header to verbose file and invoke application benchmarks
		if [ "$applications" == "-y" ];
		then
			echo YOLO Benchmarks: | tee -a $verbose_filename.txt
			seperator
			benchmark_fog_app "arrPics" "./assets/yolo-assets/yoloimage.jpg" "./assets/yolo-assets/*.jpg" "YOLO"
		elif [ "$applications" == "-p" ];
		then	
			echo Pocket Sphinx Benchmarks: | tee -a $verbose_filename.txt
			seperator
			benchmark_fog_app "arrWavs" "./assets/psphinx-assets/psphinx.wav" "./assets/psphinx-assets/*.wav" "PocketSphinx"
		elif [ "$applications" == "-j" ];
		then	
			echo Aeneas Benchmarks: | tee -a $verbose_filename.txt
			seperator
			benchmark_aeneas	
		elif [ "$applications" == "-i" ];
		then	
			echo iPokeMon Benchmarks: | tee -a $verbose_filename.txt
			seperator
			start_ipokemon_server	
			benchmark_ipokemon
		elif [ "$applications" == "-k" ];
		then	
			echo iPokeMon Benchmarks: | tee -a $verbose_filename.txt
			seperator
			benchmark_ipokemon	
		elif [ "$applications" == "-l" ];
		then	
			echo FogLAMP Benchmarks: | tee -a $verbose_filename.txt
			seperator
			benchmark_fog_app "arrCurlCommands" "./assets/foglamp-assets/foglampcurlcommand.sh" "./assets/foglamp-assets/*.sh" "FogLAMP"			
		fi	
}

# benchmark iPokemon server using a jmx file to simulate user behaviour
function benchmark_ipokemon {
	# navigate to jmeter bin folder
	cd jmeter/bin 
	
	# initialise the local asset variables
	local ipokemon_jmx=../../assets/ipokemon-assets/iPokemon.jmx
	local host=''
	
	if [ "$environment" == "-c" ];
	then 
		host=$cloudpublicip # if cloud
	else
		host=$edgeaddress # if edge
	fi	

	# run jmeter using user defined variables (automation of jsx file - allows execution on the edge or cloud)
	echo "Running JMeter..."
	./jmeter -n -t $ipokemon_jmx -JHOST=$host -JDuration=$test_duration -JThreads=$users -JRamp=$ramp_up -l testresults.csv
	
	# run tautus using user defined variables (automation of jmeter jsx file) and using reporting.yaml as a parameter
	echo "Running Taurus..."
	bzt $ipokemon_jmx -o modules.jmeter.properties.HOST=$host -o modules.jmeter.properties.Duration=$test_duration -o modules.jmeter.properties.Threads=$users -o modules.jmeter.properties.Ramp=$ramp_up reporting.yaml
	
	# move and rename test data files to the results file, redirect output using 2>/dev/null
	mv testresults.csv ../../results/$jmeter_filename.csv 2>/dev/null
	mv taurusreport.csv ../../results/$taurus_filename.csv 2>/dev/null	
	mv taurusreport.xml ../../results/$taurus_filename.xml 2>/dev/null	
	
	# navigate to defog folder
	cd ../../ 
}

# setup and start the iPokeMon server
function start_ipokemon_server {
		# determine the platform/pipeline secure shell tunnel (ssh) into, and enter the iPokeMon docker container (use ctrl p & ctrl q to detach the container)
		if [ "$environment" == "-c" ] || [ "$environment" == "-b" ];
		then
			ssh -i $awskey $clouduser@$cloudaddress -t "cd defog/ipokemonbuild/iPokeMon/docker && sudo -sH && . enter.sh; bash"
		fi
		if [ "$environment" == "-e" ] || [ "$environment" == "-b" ];
		then
			ssh $edgeuser@$edgeaddress -t "cd defog/ipokemonbuild/iPokeMon/docker && sudo -sH && . enter.sh; bash"
		fi	
}
	
# determine the pipeline/platform to benchmark the applications on, invoke the calculation of real time trip and real time factor variables	
function benchmark_application {
		echo -e
		if [ "$environment" == "-c" ]; # cloud only
		then
			benchmark_cloud_applications
			calc_rtt
			if [ "${metricsValues[5]}" != "NA" ];
			then
				calc_rtf
			fi
			calc_cloud_cost
		fi	
		if [ "$environment" == "-e" ]; # edge only
		then
			benchmark_edge_applications
			calc_rtt
			if [ "${metricsValues[5]}" != "NA" ];
			then
				calc_rtf
			fi
			calc_edge_cost
		fi
		if [ "$environment" == "-b" ]; # cloud/edge
		then
			benchmark_both_applications
			calc_rtt
			if [ "${metricsValues[5]}" != "NA" ];
			then
				calc_rtf
			fi
			calc_edge_cost
		fi
		echo -e
		echo -e "DeFog Metrics:"
		echo -e ${metricsValues[@]} | tee -a $metrics_verbose_filename.txt
}

# benchmark fog application - accepts asset array name, asset name, asset path and application name as parameters.
function benchmark_fog_app {

	# evaluate paramaters and initialise variables
	eval array_name="$1"
	eval new_asset_name="$2"
	eval asset_path="$3"
	eval application_name="$4"

	# declare asset array, asset name and counter
	declare -a $array_name
	newassetname=$new_asset_name		
	local count=1
	
	# iterate over all assets in an asset folder
	for file in $asset_path
	do
		# reset/create the metric array
		create_metric_array
		
		# Update the pipeline and application metric values
		metricsValues[17]=$pipeline
		metricsValues[18]=$application_name
		
		# Output to the terminal and results file using tee
		echo -e "" | tee -a $verbose_filename.txt
		echo $application_name Benchmark Run $count: | tee -a $verbose_filename.txt
		echo "" | tee -a $verbose_filename.txt
		
		# update array and asset variables for the current iteration
		array_name=("${assets_name[@]}" "$file")
		asset=$array_name
		
		# invoke the secure copy protocol asset function
		echo -e "Sending asset at path: " $asset "to application..."
		scp_asset
		echo -e "DONE - transferring asset payload to destination"
		
		# invoke the benchmark_application function
		benchmark_application
		
		# increment counter
		((count++))

	done
}

#
function benchmark_aeneas {

	declare -a arrAudios
	
	for file1 in ./assets/aeneas-assets/audio/*.mp3
	do
		arrAudios=("${arrAudios[@]}" "$file1")
	done

	declare -a arrTexts
	
	for file2 in ./assets/aeneas-assets/text/*.xhtml
	do
		local arrTexts=("${arrTexts[@]}" "$file2")	
	done	
			
	total=${#arrAudios[@]}
	
	local count=1
	
	for (( j=0; j<=$(( $total -1 )); j++ ))
	do 
		
		multiassets="true"
		create_metric_array
		
		metricsValues[17]=$pipeline
		metricsValues[18]="Aeneas"

		echo -e "" | tee -a $verbose_filename.txt
		echo Aeneas Benchmark Run $count: | tee -a $verbose_filename.txt
		echo "" | tee -a $verbose_filename.txt
		
		asset=${arrAudios[$j]}
		newassetname=./assets/aeneas-assets/aeneasaudio.mp3

		echo "Sending asset at path: " $asset "to application..."
		scp_asset
		echo "DONE"
		
		local oldT1=${metricsValues[0]}
		local oldbu1=${metricsValues[7]}
		
		metricsValues[0]=$oldT1
		metricsValues[7]=$oldbu1
		
		asset=${arrTexts[$j]}
		newassetname=./assets/aeneas-assets/aeneastext.xhtml
		
		if [ "$environment" != "-b" ];
		then
			echo -e "Sending asset at path: " $asset "to application..."
			scp_asset
			echo "DONE"		
		fi	
		
		if [ "$environment" == "-b" ];
		then
			local shortasset="${asset##*/}"
			echo $shortasset > ./aeneas.txt
			
			asset=./aeneas.txt
			newassetname=./aeneas.txt
			
			echo -e "Sending asset at path: " $asset "to application..."
			scp_asset
			echo "DONE"		
		fi	
				
		benchmark_application
		
		((count++))
	
	done

}

# instantiate or reset metric labels and values to default values
function create_metric_array {
	declare -g metricsLabels=('T1' 'ET' 'T2' 'T3' 'RTT' 'RTF' 'Cost' 'BytesUp1' 'BytesDown1' 'BytesDown2' 'BytesPerSecUp1' 'BytesPerSecDown1' 'BytesPerSecDown2' 'T4' 'CL' 'FRTT' 'FCL' 'Pipeline' 'Application')
	declare -g metricsValues=('NA' 'NA' 'NA' 'NA' 'NA' 'NA' 'NA' 'NA' 'NA' 'NA' 'NA' 'NA' 'NA' 'NA' 'NA' 'NA' 'NA' 'NA')	
}

# secure copy/transfer data/assets to destination platform
function scp_asset {
	TIMEFORMAT=%R # set time format
	cp $asset $newassetname 
	local start=$(date +%s.%N) # start timer to calculat ethe time it takes to transfer data
		
	# transfer data to the cloud and set array metrics to local variable	
	if [ "$environment" == "-c" ]; # cloud only
	then
		local transfer_cloud=$(scp -v -i $awskey $newassetname $clouduser@$cloudaddress:~/defog/assets 2>&1 | grep "Transferred") 		
		local newval=${transfer_cloud//[!0-9\\ \\.]/}
		newarr1=(`echo ${newval}`);
	fi	
	
	# transfer data to the edge and set array metrics to local variable	
	if [ "$environment" == "-e" ] || [ "$environment" == "-b" ]; # edge only or cloud/edge
	then
		local transfer_edge=$(scp -v $newassetname $edgeuser@$edgeaddress:~/defog/assets 2>&1 | grep "Transferred") 		
		local newval=${transfer_edge//[!0-9\\ \\.]/}
		newarr1=(`echo ${newval}`);
	fi
	
	# determine the time taken to transfer data
	local end=$(date +%s.%N)
	local runtime=$( echo "$end - $start" | bc -l )
	
	# if running an application that sends multiple assets - sum the bytes sent and time taken to transfer the assets
	if [ "$multiassets" == "true" ] && [ "${metricsValues[0]}" != "NA" ];
	then
		metricsValues[0]=$(bc <<< "${metricsValues[0]}+$runtime")
		metricsValues[7]=$(bc <<< "${metricsValues[7]}+${newarr1[0]}")
		local bytesUpVar=$(bc <<< "scale=10;${metricsValues[7]}/${metricsValues[0]}")
		metricsValues[10]=$(bc <<< "$bytesUpVar")
	else
		metricsValues[0]=$runtime
		metricsValues[7]=${newarr1[0]}
		metricsValues[10]=$(bc <<< "scale=10;${metricsValues[7]}/${metricsValues[0]}")
	fi	
	
	# remove duplicate asset
	rm $newassetname 2>/dev/null

}

# transfer the configuration file securely to the cloud or the edge using secure copy protocol. The destination platform is passed in as a paramater. Redirect the console output using 2>&1.
function transfer_config {
	# evaluate the destination platform id parameter
	eval config_destination="$1"
	
	if [ "$config_destination" == "1" ] || [ "$config_destination" == "2" ]; then # if edge or cloud/edge
		echo -e "Transferring config to the Edge:"
			scp $configslocation $edgeuser@$edgeaddress:~/defog/configs > /dev/null 2>&1
	fi	
	if [ "$config_destination" == "0" ] || [ "$config_destination" == "2" ]; then # if cloud or cloud/edge
		echo -e "Transferring configuration files to the Cloud:"
			scp -i $awskey $configslocation $clouduser@$cloudaddress:~/defog/configs 2>&1
	fi
	echo -e "DONE - Transferring configuration files"
	echo -e
}

# utility function to print verbose sepeartor/formatter line to file using tee
function seperator {
	echo -e "*****************************************************************************" | tee -a $verbose_filename.txt
}

# main functionality - invoke the create_metric_array function, output the metric labels to the result file. Determine the pipeline to run based on input sourced from the defog.sh script.
# transfer the config file to the Edge r Cloud and run the action or application functions. Cat and command line utility tr -s is used to parse and format the results data to a csv output file.
# The output files are then moved to the results folder 
function main {

	# invoke the creation of the metric array
	create_metric_array
	
	# output the lavels to the results file
	echo ${metricsLabels[@]} >> $metrics_verbose_filename.txt
	
	# handle the pipeline specific actions/application benchmarks
	if [ "$environment" == "-c" ]; # cloud only
	then
		
		benchmark_cloud_actions
		transfer_config "0"
		benchmark_applications
	fi	
	
	if [ "$environment" == "-e" ]; # edge only
	then	
		benchmark_edge_actions
		transfer_config "1"
		benchmark_applications
	fi	
	
	if [ "$environment" == "-b" ]; # cloud/edge
	then			
		benchmark_both_actions
		transfer_config "2"
		benchmark_applications
	fi	
	
	# parase and format the captured metric data and output to a csv file. Using the correct naming convention variable. The output is redirected to remove unnecessary terminal output
	cat $metrics_verbose_filename.txt | tr -s '[:blank:]' ',' > $metrics_verbose_filename.csv 2>/dev/null
	
	# move the results files to the results output and redirect terminal std:: output
	mv $verbose_filename.txt results/ 2>/dev/null
	mv $metrics_verbose_filename.txt results/ 2>/dev/null
	mv $metrics_verbose_filename.csv results/ 2>/dev/null
	rm results.txt 2>/dev/null
}

main
